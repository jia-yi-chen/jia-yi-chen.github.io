<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="MARJu3erA7Z6jybcmR5fgSNRNtCNYMAYkk0jidGGr8A">
<!-- Avoid warning on Google Chrome
        Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'interest-cohort'.
        see https://stackoverflow.com/a/75119417
    -->
    <meta http-equiv="Permissions-Policy" content="interest-cohort=()">

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Jiayi  Chen</title>
    <meta name="author" content="Jiayi  Chen">
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon_v2.ico">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://jia-yi-chen.github.io/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <!-- Social Icons -->
          <div class="navbar-brand social">
            <a href="mailto:%6A%63%34%74%64@%76%69%72%67%69%6E%69%61.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=f3Iz6qoAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/jia-yi-chen" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/jychen233" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            

          </div>
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
            <span style="font-weight: 500">Jiayi</span>
              
              Chen  <br class="d-md-none">(陈
                <span style="font-weight: 500">嘉怡</span>)
          </h1>
          <p class="desc"></p>
        </header>

        <article>
          <div class="profile float-right">

              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/icon-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/icon-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/icon-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/icon.jpg" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="icon.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

            <div class="address d-none d-md-block">
              <p>Rice Hall</p> <p>85 Engineer's Way </p> <p>Charlottesville </p> <p>VA 22904, USA</p>

            </div>
          </div>

          <div class="clearfix">
            <p>I am a Ph.D. candidate at <a href="https://www.virginia.edu" rel="external nofollow noopener" target="_blank">University of Virginia</a> majoring in <a href="https://engineering.virginia.edu/departments/computer-science" rel="external nofollow noopener" target="_blank">Computer Science</a>. 
I am advised by Prof. <a href="https://scholar.google.com/citations?user=O8XxkE4AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Aidong Zhang</a>.
My research interests are broadly in Machine Learning and Data Mining, with the focuses on Multimodal Machine Learning, Graph Mining, Continual Learning, Federated Learning, and Model-efficient Transfer Learning.</p>

<p>Prior to PhD, I received my Bachelor’s degree in Automation Engineering in 2015 and Master’s degree in Control Science and Engineering in 2018 from <a href="http://en.hit.edu.cn/" rel="external nofollow noopener" target="_blank">Xi’an Jiaotong University</a>. I was affiliated with the Institute of Artificial Intelligence and Robotics during 2015-2018, under the supervision of Prof. <a href="https://research.com/u/nanning-zheng" rel="external nofollow noopener" target="_blank">Nanning Zheng</a> and Prof. <a href="https://www.semanticscholar.org/author/Xuguang-Lan/2498428" rel="external nofollow noopener" target="_blank">Xuguang Lan</a>, working on projects related to Computer Vision, 3D Neural Stylistic Rendering, and Robotics.<!-- I am passionate about exploring AL/ML/CV/NLP potentials in daily lives! --></p>

<!-- Hi! I am currently a fifth-year Ph.D. student at MIT majoring in Electrical Engineering and Computer Science. -->
<!-- My research focuses on machine learning and developing robust and efficient algorithms driven by clinical problems.
Applications include motion-robust 3D rendering of the human brain, real-time quality assessment in MR scans as well as pose estimation and motion characterization of fetuses. -->

<p>I also did summer internships at Google in 2022 and 2023, working on Multimodal Few-shot Learning, LLMs, and Efficient Personalization.</p>

<!-- I love Visual Art, Oceanography and Astronomy. I enjoy drawing and painting in my free time! -->

          </div>

          <!-- News -->
          <h2><a href="/news/" style="color: inherit;">news</a></h2>          <div class="news">
            <div class="table-responsive">
              <table class="table table-sm table-borderless">
              
                <tr>
                  <th scope="row">Oct 9, 2023</th>
                  <td>
                    We got 2 papers accepted by <a href="https://2023.emnlp.org/" rel="external nofollow noopener" target="_blank">EMNLP 2023</a>!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Jun 6, 2023</th>
                  <td>
                    I joined YouTube-WatchNext and DeepMind-Brain-STAR teams for a summer internship at Google!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Jun 1, 2023</th>
                  <td>
                    Our paper entitled “On Hierarchical Disentanglement of Interactive Behaviors for Multimodal Spatiotemporal Data with Incompleteness” is accepted by <a href="https://dl.acm.org/doi/abs/10.1145/3580305.3599448" rel="external nofollow noopener" target="_blank">KDD’23</a> Research Track!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Apr 22, 2023</th>
                  <td>
                    I successfully proposed my Doctoral Thesis on “Spatiotemporally Collaborative Multimodal Machine Learning”!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Sep 18, 2022</th>
                  <td>
                    I will have an oral presetation on <a href="https://doi.org/10.1007/978-3-031-16446-0_1" rel="external nofollow noopener" target="_blank">Slice-to-Volume Registration Transformer (SVoRT)</a> at MICCAI 2022!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Aug 8, 2022</th>
                  <td>
                    Our paper entitled “FedMSplit: Correlation-adaptive Federated Multitask Learning across Multimodal Split Networks” was accepted by <a href="https://dl.acm.org/doi/abs/10.1145/3534678.3539384" rel="external nofollow noopener" target="_blank">KDD’22</a> Research Track!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Jun 6, 2022</th>
                  <td>
                    I join the DarkMatter Team at Google Cloud DocAI as a summer intern.

                  </td>
                </tr>
                <tr>
                  <th scope="row">Apr 22, 2022</th>
                  <td>
                    A paper “Topological Transduction for Hybrid Few-shot Learning” accepted by WWW’22 Research Track!
<!-- A paper "Topological Transduction for Hybrid Few-shot Learning” accepted by WWW'22 Research Track! -->

                  </td>
                </tr>
              </table>
            </div>
          </div>

          <!-- Latest posts -->
          

          <!-- Selected papers -->
          <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2>
          <div class="publications">
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="kdd22png" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/kdd22.png"><div id="kdd22png-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('kdd22png-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="kdd22png-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("kdd22png-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('kdd22png');
      var modalImg = document.getElementById("kdd22png-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="10.1145/3534678.3539384" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">FedMSplit: Correlation-Adaptive Federated Multi-Task Learning across Multimodal Split Networks</div>
    <!-- Author -->
    <div class="author">
      

      <em>Jiayi Chen</em>, and Aidong Zhang</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2022
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://doi.org/10.1145/3534678.3539384" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>With the advancement of data collection techniques, end users are interested in how different types of data can collaborate to improve our life experiences. Multimodal Federated Learning (MFL) is an emerging area allowing many distributed clients, each of which can collect data from multiple types of sensors, to participate in the training of some multimodal data-related models without sharing their data. In this paper, we address a novel challenging issue in MFL, the modality incongruity, where clients may have heterogeneous setups of sensors and their local data consists of different combinations of modalities. With the modality incongruity, clients may solve different tasks on different parameter spaces, which escalates the difficulties in dealing with the statistical heterogeneity problem of federated learning; also, it would be hard to perform accurate model aggregation across different types of clients. To tackle these challenges, in this work, we propose the FedMSplit framework, which allows federated training over multimodal distributed data without assuming similar active sensors in all clients. The key idea is to employ a dynamic and multi-view graph structure to adaptively capture the correlations amongst multimodal client models. More specifically, we split client models into smaller shareable blocks and allow each type of blocks to provide a specific view on client relationships. With the graph representation, the underlying correlations between clients can be captured as the edge features in the multi-view graph, and then be utilized to promote local model relations through the neighborhood message passing in the graph. Our experimental results demonstrate the effectiveness of our method under different sensor setups with statistical heterogeneity.</p>
    </div>
  </div>
</div>
</li>
<li>
<!-- _layouts/bib.html -->
<div class="row">
  <div class="col-sm-2 preview">
<img id="kdd23png" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/kdd23.png"><div id="kdd23png-modal" class="modal2">
      <span class="closeimg" onclick="document.getElementById('kdd23png-modal').style.display='none'">×</span>
      <div class="myCaption"></div>
      <img class="modal-content2" id="kdd23png-modal-img">
    </div>
    <script>
      // Get the modal
      var modal = document.getElementById("kdd23png-modal");
      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var img = document.getElementById('kdd23png');
      var modalImg = document.getElementById("kdd23png-modal-img");
      var captionText = modal.getElementsByTagName('div')[0];
      img.onclick = function () {
        modal.style.display = "block";
        modalImg.src = this.src;
        captionText.innerHTML = "";
      }
      // Get the <span> element that closes the modal
      var span = modal.getElementsByTagName('span')[0];
      // When the user clicks on <span> (x), close the modal
      span.onclick = function () {
        modal.style.display = "none";
      }
      modal.onclick = function () {
        modal.style.display = "none";
      }
    </script>
</div>

  <!-- Entry bib key -->
  <div id="10.1145/3580305.3599448" class="col-sm-8 col-md-9">
    <!-- Title -->
    <div class="title">On Hierarchical Disentanglement of Interactive Behaviors for Multimodal Spatiotemporal Data with Incompleteness</div>
    <!-- Author -->
    <div class="author">
      

      <em>Jiayi Chen</em>, and Aidong Zhang</div>

    <!-- Journal/Book title and date -->
    
    
    <div class="periodical">
      <em>In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2023
    </div>
    <div class="periodical">
      
    </div>

    <!-- Links/Buttons -->
    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://doi.org/10.1145/3580305.3599448" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a>
    </div>
    
    <div class="badges">
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Multimodal spatiotemporal data (MST) consists of multiple simultaneous spatiotemporal modalities that interact with each other in a dynamic manner. Due to the complexity of MST and the recent desire for the explainability of artificial intelligent systems, disentangled representation learning for MST (DisentMST) has become a significant task, which aims to learn disentangled representations that can expose the underlying spatial semantics, temporal dynamic patterns, and inter-modality interaction modes of the complex MST. One limitation of existing approaches is that they might fail to tolerate the real-world incomplete MST data, where missing information might break the cross-modal spatiotemporal dynamics and bring noise and ambiguity to the learning process. Another limitation is that no existing work systematically reveals the structure of different types of disentangled information. To tackle the two limitations, we define a novel two-level hierarchically structured disentanglement task for MST, which reveals informative and structured disentangled representations for MST as well as digests the real-world MST with incompleteness. We propose a new framework, BiDisentMST, which leverages Gaussian Processes and Graph Factorization on the latent space to achieve our purposes. The experimental results demonstrate the effectiveness of our proposed framework compared with baselines with respect to disentanglement and imputation results.</p>
    </div>
  </div>
</div>
</li>
</ol>
          </div>


          <!-- Social -->
            <div class="social">
              <div class="contact-icons">
                <a href="mailto:%6A%63%34%74%64@%76%69%72%67%69%6E%69%61.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=f3Iz6qoAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/jia-yi-chen" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/jychen233" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            

              </div>

              <div class="contact-note">
                
              </div>

            </div>
        </article>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Jiayi  Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.
Last updated: October 24, 2023.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NYJ88YK0VS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-NYJ88YK0VS');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
