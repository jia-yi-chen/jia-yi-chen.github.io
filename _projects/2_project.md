---
layout: page
title: Knowledge-guided 3D Stylistic Rendering
description: Knowledge-guided Neural Stylistic Image Generation given 3D Scene Models
img: assets/img/stylisticrend.png
importance: 4
category: Graphics/Vision
---

03/2017 â€“ 02/2018

- ***Keywords:*** Computer Vision, Neural Style Transfer 
- Studied human knowledge-guided neural style transfer, focusing on improving the illusion of space in generated images by simulating how artists harness skills to understand and reproduce a 3D scene (e.g., geometric structures, lighting and shallow); also studied 3D non-photorealistic rendering based on the neural style transfer paradigm.
- Proposed an illumination-guided deep alignment method using CNN, Lighting Path Expression, and PatchMatch.
- Created a 2D-3D dataset, including 3D models rendered by multiple types of lighting (by Maya), 2D photos annotated by lighting and segmentation (by Photoshop and Matlab), and a hand-drawn stylistic material for testing (CorelPainter).
- Task 1: 3D model non-photorealistic rendering
- Task 2: Low-quality Image non-photorealistic rendering


<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/stylisticrend.png" title="3d-to-2d Art dataset" class="img-fluid rounded z-depth-1" %}
    </div>
</div>